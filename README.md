# Лабораторные работы по методам оптимизации.
## Лабораторная работа №1. Методы одномерного поиска нулевого порядка.
1. **Дихотомия** или **метод половинного деления**
алгоритм поиска экстремума функции нулевого порядка, который предполагает поиск экстремума функции путём разделения **промежутка неопределённости** пополам и **исследования функции на монотонность** в центральной точке. Дихотомия считается самым неэффективным алгоритмом с точки зрения вычислительной сложности, так как **измерение целевой функции** осущесствляется дважды за одну итерацию.
2. **Золотое сечение**
лгоритм поиска экстремума функции нулевого порядка, который использует пропорцию золотого сечения для разбиения **промежутка неопределённости**. Имеет меньшую вычислительную сложность, чем **метод дихотомии** при одинаковых условиях (**lhs**, **rhs** и **eps**). Количество **измерений целевой функции** равно количеству итераций метода + 2.
3. Метод поиска **Фибоначчи**
алгоритм поиска экстремума функции нулевого порядка, который использует пропорцию пары чисел фибоначии для разбиения **промежутка неопределённости**. В отличии от двух методов выше позволяет заранее определить количество итераций метода для достижения поставленной точности по формуле $$L_{n}>\frac{rhs - lhs}{\varepsilon}$$, здесь $$n$$ - номер числа фибоначии/количество итераций. **Метод Фибоначчи** работает точнее, чем **золотое сечение** при одинаковом количестве **измерений функций**.чем  Количество **измерений целевой функции** равно количеству итераций метода + 2.

## Лабораторная работа №2. Методы многомерного поиска нулевого порядка.
1. **Дихотомия** или **метод половинного деления**
Метод поиска половинным делением необходимо модифицировать для поиска по направлению из точки пространства $$\vec{lhs}$$ в точку $$\vec{rhs}$$. Областью поиска будет отрезок из $$\vec{lhs}$$ в точку $$\vec{rhs}$$. Количество **измерений целевой функции** равно количеству итераций метода * 2.
2. **Золотое сечение**
Метод поиска золотым сечением необходимо модифицировать для поиска по направлению из точки пространства $$\vec{lhs}$$ в точку $$\vec{rhs}$$. Областью поиска будет отрезок из $$\vec{lhs}$$ в точку $$\vec{rhs}$$. Количество **измерений целевой функции** равно количеству итераций метода + 2.
3. **Метод поиска Фибоначчи**  
Метод поиска Фибоначчи необходимо модифицировать для поиска по направлению из точки пространства $$\vec{lhs}$$ в точку $$\vec{rhs}$$. Областью поиска будет отрезок из $$\vec{lhs}$$ в точку $$\vec{rhs}$$. Количество итераций метода для достижения поставленной точности можно определить по формуле $$L_{n}>\frac{|\vec{rhs} - \vec{lhs}|}{\varepsilon}$$, здесь $$n$$ - номер числа фибоначии/количество итераций.
4. **Метод покоординатного спуска**  
Метод покоординатного спуска позволяет обнаружить эстремум **целевой функции** путём последовательного поиска по направлениям орт пространства, которому принадлежит аргумент функции. Алгоритму необходимо указать точку из которой мы начинаем поис $$\vec{x_{0}}$$, количество итераций, точность $$\varepsilon$$ и длину шага $$\lambda$$ поиска вдоль одного орта.

## Лабораторная работа №3. Методы многомерного поиска высших порядков. Функции штрафа.
1. **Градиентный спуск спуск**  
   **Градиентный спуск спуск** представляет собой итерационный алгоритм, который можно предстваить в виде следующей рекурентной последовательности: $$\vec{x_{i+1}}=\vec{x_{i}}+\lambda\vec{\nabla}\bullet f\left(\vec{x_{i}}\right)$$, где $$\lambda=\text{argmin}\left(f\left(\left[\vec{x_{i}},\vec{x_{i}}+\lambda\vec{\nabla}\bullet f\left(\vec{x_{i}}\right)\right]\right)\right)$$, здесь $$\vec{\nabla}\bullet f\left(\vec{x}\right)$$ - вектор градиента скалярной функции вектороного аргумента, $$i$$-ый элемент которого: $$\frac{\partial f\left(\vec{x}\right)}{\partial x_{i}}$$. Для языков программирования: **C++**, **Java**, **C#**, реализован рассчёт градиента функции в точке. Производные выражаются через центральный разностный аналог $$\frac{df\left(x\right)}{dx}=\frac{f\left(x+dx\right)-f\left(x-dx\right)}{2dx}$$ с $$dx=10^{-6}$$.
2. **Метод сопряжённых градиентов**  
   **Метод сопряжённых градиентов** представляет собой итерационный алгоритм, который можно предстваить в виде следующей рекурентной последовательности, для которой на первом шаге мы определяем:
3. **Метод Ньютона-Рафсона**  
   **Метод Ньютона-Рафсона** представляет собой итерационный алгоритм, который можно предстваить в виде следующей рекурентной последовательности:

4. **Функции внешнего и внутреннего штрафа**  
Основная идея заключается в том, что мы преобразуем исходную задачу с набором условий, как равенств так и неравенств к безусловной задчи оптимизации. Например для задачи:

**Внутренний штраф**  
**Метод применяется для решения задач оптимизации с ограничениями в виде неравенств**. Идея внутреннего штрафа предполагает, что значения штрафных функций начинают неограниченно возрастать по мере приближения к границе допустимой области $$G$$. Функция внутреннего штрафа $$\varPhi\left(\lambda,\vec{x}\right)$$ должна удовлетворять следующим условиям:  
   - Быть равной нулю или меньше точности $$\varepsilon$$ внутри области поиска, а именнно: $$0,\text{if},\vec{x}\in G;$$
   - Неограниченно возрастать по мере приближения к границе области поиска: $$\infty,\text{if},\vec{x}\notin G,\lambda\rightarrow0;$$
   - Иметь разрыв на границе области поиска: $$\infty,\text{if},\vec{x}\in G,\vec{x}\rightarrow\partial G.$$

**Внешний штраф**  
**Метод применяется для рещения задач с ограничениями как в виде неравенств, так и равенств**. Функции штрафа выбираются исходя из соображений о том, что внутри допустимой области и на ее границах их значения равны нулю, а вне допустимой области $$G$$ возрастают - чем больше, тем сильнее нарушаются ограничения. Таким образом штрафуется удаление от допустимой области. Функция внешнего штрафа $$\varPhi\left(\lambda,\vec{x}\right)$$  должна удовлетворять следующим условиям:  
 - Быть равной нулю или меньше точности $$\varepsilon$$ внутри области поиска, а именнно: $$0,\text{if},\vec{x}\in G;$$
 - Неограниченно возрастать по мере оталения от границе области для любой точки $$\vec{x}$$ не принадлежащей области поиска: $$\infty,\text{if},\vec{x}\notin G,\lambda\rightarrow0;$$  
